----- Chinese
# AWS DynamoDB US-EAST-1 åŒºåŸŸä¸­æ–­äº‹æ•…æ€»ç»“ï¼ˆSREè§†è§’ï¼‰

## ðŸ“‹ äº‹æ•…æ¦‚è§ˆ

2025å¹´10æœˆ19æ—¥ï¼ŒAWSæœ€é‡è¦çš„åŒºåŸŸUS-EAST-1å‘ç”Ÿäº†ä¸€æ¬¡ä¸¥é‡çš„æœåŠ¡ä¸­æ–­ï¼ŒæŒç»­çº¦14.5å°æ—¶ï¼Œå½±å“äº†DynamoDBã€EC2ã€Lambdaã€ECSç­‰å¤šä¸ªæ ¸å¿ƒæœåŠ¡ã€‚è¿™æ¬¡äº‹æ•…çš„æ ¹æœ¬åŽŸå› æ˜¯ä¸€ä¸ªçœ‹ä¼¼ç®€å•ä½†æžå…¶è‡´å‘½çš„ç«žæ€æ¡ä»¶ï¼ˆRace Conditionï¼‰é—®é¢˜ã€‚

ä½œä¸ºSREï¼Œæˆ‘ä»¬éœ€è¦æ·±å…¥ç†è§£è¿™æ¬¡äº‹æ•…çš„æŠ€æœ¯ç»†èŠ‚ã€çº§è”å½±å“ï¼Œä»¥åŠä»Žä¸­æ±²å–çš„å®è´µç»éªŒæ•™è®­ã€‚è¿™ä¸ä»…æ˜¯ä¸€æ¬¡æŠ€æœ¯æ•…éšœçš„å¤ç›˜ï¼Œæ›´æ˜¯åˆ†å¸ƒå¼ç³»ç»Ÿè®¾è®¡å’Œè¿ç»´å®žè·µçš„é‡è¦æ¡ˆä¾‹ç ”ç©¶ã€‚

æ ¸å¿ƒå…³é”®è¯ï¼š ç«žæ€æ¡ä»¶ã€DNSæ•…éšœã€çº§è”å¤±è´¥ã€TOCTOUé—®é¢˜ã€åˆ†å¸ƒå¼ç³»ç»ŸéŸ§æ€§

## ä¸€ã€å…ˆä¸¾ä¸ªä¾‹å­ï¼šä»€ä¹ˆæ˜¯Race Conditionï¼ˆç«žæ€æ¡ä»¶ï¼‰ï¼Ÿ

æƒ³è±¡ä¸€ä¸‹è¿™ä¸ªåœºæ™¯ï¼š

ä½ å’Œå®¤å‹å…±ç”¨ä¸€ä¸ªå†°ç®±ã€‚æŸå¤©æ™šä¸Šï¼Œä½ ä¿©éƒ½å‘çŽ°ç‰›å¥¶å¿«æ²¡äº†ï¼š
- æ™šä¸Š10ç‚¹ï¼šä½ çœ‹äº†ä¸€çœ¼å†°ç®±ï¼Œå‘çŽ°ç‰›å¥¶è¿˜å‰©ä¸€ç‚¹ï¼Œå¿ƒæƒ³"æ˜Žå¤©æ—©ä¸Šä¹°"
- æ™šä¸Š10:05ï¼šå®¤å‹ä¹Ÿçœ‹äº†å†°ç®±ï¼Œä¹Ÿè§‰å¾—"æ˜Žå¤©æ—©ä¸Šä¹°"
- ç¬¬äºŒå¤©æ—©ä¸Š7ç‚¹ï¼šä½ åŽ»è¶…å¸‚ä¹°äº†ä¸€ç®±ç‰›å¥¶
- æ—©ä¸Š7:30ï¼šå®¤å‹ä¹ŸåŽ»è¶…å¸‚ä¹°äº†ä¸€ç®±ç‰›å¥¶
- ç»“æžœï¼šå†°ç®±é‡ŒçŽ°åœ¨æœ‰ä¸¤ç®±ç‰›å¥¶ï¼Œæµªè´¹äº†ï¼

è¿™å°±æ˜¯å…¸åž‹çš„ç«žæ€æ¡ä»¶ï¼šä¸¤ä¸ªäººåŸºäºŽ"è¿‡æ—¶çš„ä¿¡æ¯"åšå†³å®šï¼Œå¯¼è‡´äº†æ„å¤–çš„ç»“æžœã€‚

åœ¨è®¡ç®—æœºç³»ç»Ÿä¸­ï¼Œè¿™ç§é—®é¢˜æ›´åŠ è‡´å‘½ã€‚æ¯”å¦‚ï¼š
- è¿›ç¨‹Aæ£€æŸ¥"æ–‡ä»¶æ˜¯å¦å­˜åœ¨" â†’ ä¸å­˜åœ¨ â†’ å‡†å¤‡åˆ›å»º
- è¿›ç¨‹Bä¹Ÿæ£€æŸ¥"æ–‡ä»¶æ˜¯å¦å­˜åœ¨" â†’ ä¸å­˜åœ¨ â†’ å‡†å¤‡åˆ›å»º  
- ä¸¤ä¸ªè¿›ç¨‹åŒæ—¶åˆ›å»º â†’ ðŸ’¥ å†²çªï¼

---

## äºŒã€è¿™æ¬¡AWSç”Ÿäº§äº‹æ•…åˆ°åº•å‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿ

### ðŸ“… äº‹æ•…æ—¶é—´çº¿
- 2025å¹´10æœˆ19æ—¥ 23:48 PDT - äº‹æ•…å¼€å§‹
- 2025å¹´10æœˆ20æ—¥ 14:20 PDT - å®Œå…¨æ¢å¤
- å½±å“æ—¶é•¿ï¼šçº¦14.5å°æ—¶
- å½±å“èŒƒå›´ï¼šAWSæœ€å¤§çš„åŒºåŸŸ US-EAST-1ï¼ˆåŒ—å¼—å‰å°¼äºšï¼‰

### ðŸŽ¯ æ ¸å¿ƒé—®é¢˜ï¼šDynamoDBçš„DNSç«žæ€æ¡ä»¶

AWS DynamoDBæœ‰ä¸€ä¸ªè‡ªåŠ¨åŒ–çš„DNSç®¡ç†ç³»ç»Ÿï¼ŒåŒ…å«ä¸¤ä¸ªç»„ä»¶ï¼š

1. DNSè§„åˆ’å™¨ï¼ˆDNS Plannerï¼‰ï¼šè´Ÿè´£ç›‘æŽ§è´Ÿè½½å‡è¡¡å™¨å¥åº·çŠ¶æ€ï¼Œå®šæœŸç”Ÿæˆæ–°çš„DNSè§„åˆ’
2. DNSæ‰§è¡Œå™¨ï¼ˆDNS Enactorï¼‰ï¼šåœ¨3ä¸ªå¯ç”¨åŒºç‹¬ç«‹è¿è¡Œï¼Œè´Ÿè´£å°†DNSè§„åˆ’åº”ç”¨åˆ°Route53
ä¸ºä¿è¯éŸ§æ€§ï¼ŒDNS æ‰§è¡Œå™¨åœ¨ä¸‰ä¸ªä¸åŒçš„å¯ç”¨åŒº (AZ) ä¸­ä»¥å†—ä½™ä¸”å®Œå…¨ç‹¬ç«‹çš„æ–¹å¼è¿è¡Œã€‚æ¯ä¸ªç‹¬ç«‹çš„ DNS æ‰§è¡Œå™¨å®žä¾‹éƒ½ä¼šæŸ¥æ‰¾æ–°çš„è§„åˆ’ï¼Œå¹¶å°è¯•é€šè¿‡ Route53 äº‹åŠ¡å°†å½“å‰è§„åˆ’æ›¿æ¢ä¸ºæ–°è§„åˆ’ï¼Œè¿™æ ·å³ä½¿å¤šä¸ª DNS æ‰§è¡Œå™¨åŒæ—¶å°è¯•æ›´æ–°åŒä¸€ä¸ªç»ˆç«¯èŠ‚ç‚¹ï¼Œä¹Ÿèƒ½ç¡®ä¿æ¯ä¸ªç»ˆç«¯èŠ‚ç‚¹éƒ½èƒ½ä»¥ä¸€è‡´çš„è§„åˆ’å®Œæˆæ›´æ–°ã€‚æ­£å¸¸æƒ…å†µä¸‹ï¼ŒDNS æ‰§è¡Œå™¨ä¼šèŽ·å–æœ€æ–°çš„è§„åˆ’ï¼Œå¹¶å¼€å§‹é€ä¸€å¤„ç†æœåŠ¡ç»ˆç«¯èŠ‚ç‚¹ä»¥åº”ç”¨è¯¥è§„åˆ’ã€‚è¿™ä¸ªè¿‡ç¨‹é€šå¸¸èƒ½å¿«é€Ÿå®Œæˆï¼Œæœ‰æ•ˆç¡®ä¿ DNS çŠ¶æ€å§‹ç»ˆä¿æŒæœ€æ–°ã€‚
ä¸å¹¸çš„æ˜¯ï¼Œä¸€ä¸ª DNS æ‰§è¡Œå™¨åœ¨æ›´æ–°å¤šä¸ª DNS ç»ˆç«¯èŠ‚ç‚¹æ—¶é‡åˆ°äº†å¼‚å¸¸é«˜çš„å»¶è¿Ÿï¼Œéœ€è¦ä¸æ–­é‡è¯•ã€‚æ•…éšœå°±è¿™æ ·å¼€å§‹äº†ï¼š
#### ðŸ’£ è‡´å‘½çš„ç«žæ€æ¡ä»¶æ˜¯è¿™æ ·å‘ç”Ÿçš„ï¼š

```
æ—¶é—´è½´ï¼š
T1: æ‰§è¡Œå™¨A å¼€å§‹åº”ç”¨"æ—§è§„åˆ’V1"ï¼ˆä½†å¤„ç†å¾ˆæ…¢ï¼Œé‡åˆ°å¼‚å¸¸å»¶è¿Ÿï¼‰
T2: è§„åˆ’å™¨ ç”Ÿæˆäº†"æ–°è§„åˆ’V2"ã€"V3"ã€"V4"...
T3: æ‰§è¡Œå™¨B å¿«é€Ÿåº”ç”¨äº†"æœ€æ–°è§„åˆ’V5"ï¼Œå®Œæˆæ‰€æœ‰ç»ˆç«¯èŠ‚ç‚¹æ›´æ–°
T4: æ‰§è¡Œå™¨B å¯åŠ¨æ¸…ç†æµç¨‹ï¼Œåˆ é™¤"å¤ªæ—§çš„è§„åˆ’"ï¼ˆåŒ…æ‹¬V1ï¼‰
T5: æ‰§è¡Œå™¨A ç»ˆäºŽå®Œæˆå¤„ç†ï¼ŒæŠŠ"æ—§è§„åˆ’V1"åº”ç”¨åˆ°DynamoDBåŒºåŸŸç»ˆç«¯èŠ‚ç‚¹
    âš ï¸ é—®é¢˜ï¼šæ‰§è¡Œå™¨Aåœ¨å¼€å§‹æ—¶æ£€æŸ¥è¿‡"V1æ¯”ä¹‹å‰çš„è§„åˆ’æ–°"ï¼Œä½†çŽ°åœ¨è¿™ä¸ªæ£€æŸ¥å·²ç»è¿‡æ—¶äº†ï¼
T6: æ‰§è¡Œå™¨B çš„æ¸…ç†æµç¨‹å‘çŽ°V1å¤ªæ—§ï¼Œç›´æŽ¥åˆ é™¤
T7: ðŸ’¥ ç¾éš¾ï¼šåŒºåŸŸç»ˆç«¯èŠ‚ç‚¹çš„æ‰€æœ‰IPåœ°å€è¢«ç§»é™¤ï¼ŒDNSè§£æžå¤±è´¥ï¼
```

### ðŸ”¥ è¿žé”ååº”ï¼ˆé›ªå´©æ•ˆåº”ï¼‰

1. DynamoDBä¸å¯ç”¨ (23:48 - 02:40)
   - æ‰€æœ‰é€šè¿‡å…¬å…±ç»ˆç«¯èŠ‚ç‚¹çš„è¿žæŽ¥å¤±è´¥
   - DNSè§£æžè¿”å›žç©ºè®°å½•
   - å®¢æˆ·åº”ç”¨æ— æ³•è¿žæŽ¥DynamoDB

2. EC2å®žä¾‹å¯åŠ¨å¤±è´¥ (23:48 - 13:50)
   - DWFMï¼ˆDropletå·¥ä½œæµç®¡ç†å™¨ï¼‰ä¾èµ–DynamoDB
   - ä¸Žæ‰€æœ‰dropletçš„ç§Ÿçº¦è¶…æ—¶
   - æ¢å¤æ—¶é™·å…¥"æ‹¥å¡žå´©æºƒ"ï¼šé‡è¯•ä»»åŠ¡å †ç§¯ â†’ ç§Ÿçº¦å†æ¬¡è¶…æ—¶ â†’ æ›´å¤šé‡è¯•
   - æ–°å®žä¾‹å¯åŠ¨è¿”å›ž"å®¹é‡ä¸è¶³"é”™è¯¯

3. ç½‘ç»œé…ç½®åŒæ­¥å»¶è¿Ÿ (05:28 - 10:36)
   - ç½‘ç»œç®¡ç†å™¨ç§¯åŽ‹å¤§é‡ä»»åŠ¡
   - æ–°å¯åŠ¨çš„EC2å®žä¾‹æ— æ³•èŽ·å¾—ç½‘ç»œè¿žæŽ¥

4. NLBå¥åº·æ£€æŸ¥å¤±è´¥ (05:30 - 14:09)
   - å¥åº·æ£€æŸ¥å¯¹è±¡æ˜¯ç½‘ç»œæœªå°±ç»ªçš„æ–°å®žä¾‹
   - å¥åº·çŠ¶æ€åœ¨"å¤±è´¥"å’Œ"æ­£å¸¸"ä¹‹é—´åå¤æ¨ªè·³
   - è§¦å‘å¯ç”¨åŒºDNSè‡ªåŠ¨æ•…éšœè½¬ç§»
   - éƒ¨åˆ†å®¹é‡è¢«ç§»å‡ºæœåŠ¡

5. å…¶ä»–æœåŠ¡å—å½±å“
   - Lambdaï¼šå‡½æ•°è°ƒç”¨å¤±è´¥ã€SQS/Kinesiså¤„ç†å»¶è¿Ÿ
   - ECS/EKS/Fargateï¼šå®¹å™¨å¯åŠ¨å¤±è´¥
   - Amazon Connectï¼šå‘¼å«ã€èŠå¤©ã€å·¥å•å¤„ç†é”™è¯¯
   - Redshiftï¼šæŸ¥è¯¢å¤±è´¥ã€é›†ç¾¤æ— æ³•ä¿®æ”¹
   - IAM/STSï¼šè®¤è¯å¤±è´¥ã€æŽ§åˆ¶å°ç™»å½•å¤±è´¥

---

## ä¸‰ã€ä»ŽSREè§’åº¦çš„æ·±åº¦è§£è¯»

### ðŸŽ“ è¿™æ¬¡äº‹æ•…çš„æ ¸å¿ƒæ•™è®­

#### 1ï¸âƒ£ åˆ†å¸ƒå¼ç³»ç»Ÿä¸­çš„æ—¶é—´å‡è®¾æ˜¯å±é™©çš„
SREåŽŸåˆ™ï¼š
- âš ï¸ æ°¸è¿œä¸è¦å‡è®¾"æ£€æŸ¥æ—¶çš„çŠ¶æ€"åœ¨"ä½¿ç”¨æ—¶ä»ç„¶æœ‰æ•ˆ"ï¼ˆTOCTOUé—®é¢˜ï¼‰
- âœ… åº”è¯¥ä½¿ç”¨ä¹è§‚é”æˆ–ç‰ˆæœ¬å·æœºåˆ¶åœ¨æ¯æ¬¡æ›´æ–°æ—¶éªŒè¯

#### 2ï¸âƒ£ è‡ªåŠ¨åŒ–ç³»ç»Ÿéœ€è¦"ç†”æ–­æœºåˆ¶"

DNSæ‰§è¡Œå™¨åœ¨é‡åˆ°å¼‚å¸¸å»¶è¿Ÿæ—¶ï¼Œåº”è¯¥ï¼š
- æ£€æµ‹åˆ°å¤„ç†æ—¶é—´å¼‚å¸¸ â†’ ä¸»åŠ¨æ”¾å¼ƒå½“å‰è§„åˆ’
- é¿å…"åƒµå°¸è¿›ç¨‹"ç»§ç»­æ‰§è¡Œè¿‡æ—¶çš„æ“ä½œ

ç±»æ¯”ï¼šå°±åƒä½ åŽ»è¶…å¸‚ä¹°ç‰›å¥¶ï¼Œå¦‚æžœå‘çŽ°è·¯ä¸Šå µè½¦2å°æ—¶ï¼Œåº”è¯¥æ‰“ç”µè¯ç¡®è®¤å®¤å‹æ˜¯å¦å·²ç»ä¹°äº†ï¼Œè€Œä¸æ˜¯å‚»å‚»åœ°ç»§ç»­ã€‚

#### 3ï¸âƒ£ ä¾èµ–å…³ç³»çš„çº§è”å¤±è´¥

```
DynamoDB DNSå¤±è´¥
    â†“
DynamoDBä¸å¯ç”¨
    â†“
DWFMæ— æ³•ç»´æŠ¤ç§Ÿçº¦
    â†“
EC2å®žä¾‹å¯åŠ¨å¤±è´¥
    â†“
ç½‘ç»œé…ç½®åŒæ­¥å»¶è¿Ÿ
    â†“
NLBå¥åº·æ£€æŸ¥å¤±è´¥
    â†“
Lambda/ECS/Connectç­‰æœåŠ¡å—å½±å“
```

SREåŽŸåˆ™ï¼š
- ðŸ”´ å•ç‚¹æ•…éšœï¼ˆSPOFï¼‰æ˜¯è‡´å‘½çš„
- âœ… æ ¸å¿ƒæœåŠ¡ï¼ˆå¦‚DNSã€DynamoDBï¼‰éœ€è¦å¤šåŒºåŸŸå†—ä½™
- âœ… ä¾èµ–æœåŠ¡åº”è¯¥æœ‰é™çº§æ¨¡å¼ï¼ˆGraceful Degradationï¼‰

#### 4ï¸âƒ£ æ¢å¤è¿‡ç¨‹ä¸­çš„"æ‹¥å¡žå´©æºƒ"

DWFMçš„é—®é¢˜ï¼š
```
ç§Ÿçº¦è¶…æ—¶ â†’ é‡è¯• â†’ ä»»åŠ¡å †ç§¯ â†’ å¤„ç†å˜æ…¢ â†’ ç§Ÿçº¦å†æ¬¡è¶…æ—¶ â†’ æ›´å¤šé‡è¯•
```

è¿™æ˜¯å…¸åž‹çš„æ­£åé¦ˆå¾ªçŽ¯ï¼ˆPositive Feedback Loopï¼‰ï¼Œç³»ç»Ÿè¶Šå¿™è¶Šæ…¢ï¼Œè¶Šæ…¢è¶Šå¿™ã€‚

SREè§£å†³æ–¹æ¡ˆï¼š
- âœ… é™æµï¼ˆRate Limitingï¼‰ï¼šæŽ§åˆ¶é‡è¯•é€ŸçŽ‡
- âœ… èƒŒåŽ‹ï¼ˆBackpressureï¼‰ï¼šæ ¹æ®é˜Ÿåˆ—é•¿åº¦åŠ¨æ€è°ƒæ•´
- âœ… æ–­è·¯å™¨ï¼ˆCircuit Breakerï¼‰ï¼šæ£€æµ‹åˆ°å¼‚å¸¸æ—¶æš‚åœé‡è¯•

#### 5ï¸âƒ£ ç›‘æŽ§å’Œå‘Šè­¦çš„ç›²åŒº

- DNSé—®é¢˜åœ¨23:48å‘ç”Ÿï¼Œä½†ç›´åˆ°00:38æ‰ç¡®å®šæ ¹å› ï¼ˆè€—æ—¶50åˆ†é’Ÿï¼‰
- NLBå¥åº·æ£€æŸ¥é—®é¢˜åœ¨05:30å¼€å§‹ï¼Œ06:52æ‰è¢«ç›‘æŽ§æ£€æµ‹åˆ°ï¼ˆè€—æ—¶82åˆ†é’Ÿï¼‰

SREåŽŸåˆ™ï¼š
- âš ï¸ ä½ æ— æ³•ä¿®å¤ä½ çœ‹ä¸è§çš„é—®é¢˜
- âœ… éœ€è¦ç«¯åˆ°ç«¯çš„å¥åº·æ£€æŸ¥ï¼Œè€Œä¸ä»…ä»…æ˜¯ç»„ä»¶çº§ç›‘æŽ§
- âœ… åˆæˆç›‘æŽ§ï¼ˆSynthetic Monitoringï¼‰ï¼šæ¨¡æ‹ŸçœŸå®žç”¨æˆ·è¯·æ±‚

#### 6ï¸âƒ£ æµ‹è¯•è¦†ç›–çš„ä¸è¶³

AWSæ‰¿è®¤ï¼š
> "æ­¤å‰æ²¡æœ‰é’ˆå¯¹è¿™ç§æƒ…å†µçš„æ—¢å®šè¿ç»´æ¢å¤æµç¨‹"

SREå®žè·µï¼š
- âœ… æ··æ²Œå·¥ç¨‹ï¼ˆChaos Engineeringï¼‰ï¼šä¸»åŠ¨æ³¨å…¥æ•…éšœæµ‹è¯•ç³»ç»ŸéŸ§æ€§
- âœ… ç¾éš¾æ¢å¤æ¼”ç»ƒï¼ˆDR Drillsï¼‰ï¼šå®šæœŸæ¨¡æ‹Ÿå¤§è§„æ¨¡æ•…éšœ
- âœ… Game Daysï¼šå›¢é˜Ÿåä½œæ¼”ç»ƒæ•…éšœå“åº”


### ðŸ› ï¸ AWSçš„æ”¹è¿›æŽªæ–½

1. ç«‹å³è¡ŒåŠ¨ï¼š
   - âœ… å…¨çƒç¦ç”¨DNSè‡ªåŠ¨åŒ–ç³»ç»Ÿï¼ˆå…ˆæ­¢è¡€ï¼‰
   - âœ… ä¿®å¤ç«žæ€æ¡ä»¶
   - âœ… å¢žåŠ ä¿æŠ¤æŽªæ–½é˜²æ­¢åº”ç”¨é”™è¯¯è§„åˆ’

2. ä¸­æœŸæ”¹è¿›ï¼š
   - âœ… NLBæ·»åŠ é€ŸçŽ‡æŽ§åˆ¶ï¼Œé™åˆ¶å•æ¬¡æ•…éšœè½¬ç§»ç§»é™¤çš„å®¹é‡
   - âœ… EC2æž„å»ºDWFMæ¢å¤æµç¨‹çš„æµ‹è¯•å¥—ä»¶
   - âœ… æ”¹è¿›æ•°æ®åŒæ­¥ç³»ç»Ÿçš„é™æµæœºåˆ¶

3. é•¿æœŸä¼˜åŒ–ï¼š
   - âœ… æ·±å…¥åˆ†æžæ‰€æœ‰å—å½±å“æœåŠ¡
   - âœ… å¯»æ‰¾é¿å…ç±»ä¼¼äº‹ä»¶çš„æ–¹æ³•
   - âœ… ç¼©çŸ­æ¢å¤æ—¶é—´


### ðŸŽ¯ æ€»ç»“

è¿™æ¬¡äº‹æ•…æ˜¯ä¸€ä¸ªç»å…¸çš„åˆ†å¸ƒå¼ç³»ç»Ÿç«žæ€æ¡ä»¶æ¡ˆä¾‹ï¼Œæš´éœ²äº†å‡ ä¸ªå…³é”®é—®é¢˜ï¼š

1. æ—¶é—´å‡è®¾çš„å±é™©æ€§ï¼šTOCTOUï¼ˆTime-of-Check to Time-of-Useï¼‰é—®é¢˜
2. çº§è”å¤±è´¥çš„å¨åŠ›ï¼šä¸€ä¸ªDNSé—®é¢˜å¯¼è‡´æ•´ä¸ªåŒºåŸŸå¤šä¸ªæœåŠ¡ç˜«ç—ª
3. æ¢å¤è¿‡ç¨‹çš„å¤æ‚æ€§ï¼šæ‹¥å¡žå´©æºƒã€æ­£åé¦ˆå¾ªçŽ¯
4. æµ‹è¯•è¦†ç›–çš„é‡è¦æ€§ï¼šæ²¡æœ‰æ¼”ç»ƒè¿‡çš„æ¢å¤æµç¨‹åœ¨çœŸå®žæ•…éšœæ—¶ä¼šæ‰‹å¿™è„šä¹±

æœ€é‡è¦çš„æ•™è®­ï¼š
> åœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­ï¼Œæ°¸è¿œä¸è¦ç›¸ä¿¡"è¿‡æ—¶çš„æ£€æŸ¥ç»“æžœ"ã€‚æ¯æ¬¡å…³é”®æ“ä½œå‰éƒ½è¦é‡æ–°éªŒè¯å‰ææ¡ä»¶ã€‚

è¿™å°±åƒå¼€è½¦è¿‡åå­—è·¯å£ï¼šå³ä½¿ä½ çœ‹åˆ°ç»¿ç¯ï¼Œä¹Ÿè¦åœ¨è¿›å…¥è·¯å£å‰å†æ¬¡ç¡®è®¤æ²¡æœ‰è½¦é—¯çº¢ç¯ã€‚åœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­ï¼Œè¿™ç§"äºŒæ¬¡ç¡®è®¤"æœºåˆ¶èƒ½é¿å…å¾ˆå¤šç¾éš¾æ€§æ•…éšœã€‚


----- English
# AWS DynamoDB US-EAST-1 Region Outage Incident Summary (SRE Perspective)

## ðŸ“‹ Incident Overview

On October 19, 2025, AWS's most critical region US-EAST-1 experienced a severe service disruption lasting approximately 14.5 hours, affecting multiple core services including DynamoDB, EC2, Lambda, ECS, and others. The root cause of this incident was a seemingly simple yet extremely deadly Race Condition problem.

As SREs, we need to deeply understand the technical details of this incident, its cascading impacts, and the valuable lessons learned. This is not just a technical failure post-mortem, but an important case study for distributed system design and operational practices.

Core Keywords: Race Condition, DNS Failure, Cascading Failure, TOCTOU Problem, Distributed System Resilience

## 1. First, An Example: What is a Race Condition?

Imagine this scenario:

You and your roommate share a refrigerator. One evening, you both notice the milk is running low:
- 10:00 PM: You check the fridge, see a little milk left, think "I'll buy some tomorrow morning"
- 10:05 PM: Your roommate also checks the fridge, also thinks "I'll buy some tomorrow morning"
- Next day 7:00 AM: You go to the store and buy a carton of milk
- 7:30 AM: Your roommate also goes to the store and buys a carton of milk
- Result: Now there are two cartons of milk in the fridge, wasteful!

This is a typical race condition: two people making decisions based on "outdated information," leading to unexpected results.

In computer systems, this problem is even more deadly. For example:
- Process A checks "does file exist?" â†’ No â†’ prepares to create
- Process B also checks "does file exist?" â†’ No â†’ prepares to create
- Both processes create simultaneously â†’ ðŸ’¥ Conflict!

---

## 2. What Actually Happened in This AWS Production Incident?

### ðŸ“… Incident Timeline
- October 19, 2025, 23:48 PDT - Incident begins
- October 20, 2025, 14:20 PDT - Full recovery
- Impact duration: Approximately 14.5 hours
- Impact scope: AWS's largest region US-EAST-1 (Northern Virginia)

### ðŸŽ¯ Core Problem: DynamoDB's DNS Race Condition

AWS DynamoDB has an automated DNS management system with two components:

1. DNS Planner: Monitors load balancer health status, periodically generates new DNS plans
2. DNS Enactor: Runs independently in 3 availability zones, responsible for applying DNS plans to Route53

To ensure resilience, DNS enactors run redundantly and completely independently across three different availability zones (AZs). Each independent DNS enactor instance looks for new plans and attempts to replace the current plan with the new plan through Route53 transactions, ensuring that even if multiple DNS enactors try to update the same endpoint simultaneously, each endpoint can complete updates with a consistent plan. Under normal circumstances, DNS enactors retrieve the latest plan and begin processing service endpoints one by one to apply the plan. This process typically completes quickly, effectively ensuring DNS state remains up-to-date.

Unfortunately, one DNS enactor encountered abnormally high latency when updating multiple DNS endpoints, requiring constant retries. The failure began like this:

#### ðŸ’£ How the Fatal Race Condition Occurred:

```
Timeline:
T1: Enactor A starts applying "old plan V1" (but processes slowly, encounters abnormal latency)
T2: Planner generates "new plans V2", "V3", "V4"...
T3: Enactor B quickly applies "latest plan V5", completes all endpoint updates
T4: Enactor B starts cleanup process, deletes "too old plans" (including V1)
T5: Enactor A finally completes processing, applies "old plan V1" to DynamoDB regional endpoint
    âš ï¸ Problem: Enactor A checked "V1 is newer than previous plan" at start, but this check is now outdated!
T6: Enactor B's cleanup process finds V1 too old, directly deletes it
T7: ðŸ’¥ Disaster: All IP addresses for regional endpoint are removed, DNS resolution fails!
```

### ðŸ”¥ Chain Reaction (Avalanche Effect)

1. DynamoDB Unavailable (23:48 - 02:40)
   - All connections through public endpoints fail
   - DNS resolution returns empty records
   - Client applications cannot connect to DynamoDB

2. EC2 Instance Launch Failures (23:48 - 13:50)
   - DWFM (Droplet Workflow Manager) depends on DynamoDB
   - Leases with all droplets timeout
   - During recovery, falls into "congestion collapse": retry tasks pile up â†’ leases timeout again â†’ more retries
   - New instance launches return "insufficient capacity" errors

3. Network Configuration Sync Delays (05:28 - 10:36)
   - Network manager accumulates large task backlog
   - Newly launched EC2 instances cannot obtain network connectivity

4. NLB Health Check Failures (05:30 - 14:09)
   - Health checks target new instances with unready networks
   - Health status oscillates between "failed" and "healthy"
   - Triggers availability zone DNS automatic failover
   - Partial capacity removed from service

5. Other Affected Services
   - Lambda: Function invocation failures, SQS/Kinesis processing delays
   - ECS/EKS/Fargate: Container startup failures
   - Amazon Connect: Call, chat, and ticket processing errors
   - Redshift: Query failures, cluster modification failures
   - IAM/STS: Authentication failures, console login failures

---

## 3. In-Depth Analysis from SRE Perspective

### ðŸŽ“ Core Lessons from This Incident

#### 1ï¸âƒ£ Time Assumptions in Distributed Systems Are Dangerous
SRE Principles:
- âš ï¸ Never assume "state at check time" remains valid "at use time" (TOCTOU problem)
- âœ… Should use optimistic locking or version number mechanisms to verify on each update

#### 2ï¸âƒ£ Automated Systems Need "Circuit Breaker Mechanisms"

DNS enactors should, when encountering abnormal latency:
- Detect abnormal processing time â†’ actively abandon current plan
- Avoid "zombie processes" continuing to execute outdated operations

Analogy: Like going to buy milk - if you encounter a 2-hour traffic jam, you should call to confirm whether your roommate already bought milk, rather than stubbornly continuing.

#### 3ï¸âƒ£ Cascading Failures from Dependencies

```
DynamoDB DNS failure
    â†“
DynamoDB unavailable
    â†“
DWFM cannot maintain leases
    â†“
EC2 instance launch failures
    â†“
Network configuration sync delays
    â†“
NLB health check failures
    â†“
Lambda/ECS/Connect services affected
```

SRE Principles:
- ðŸ”´ Single Points of Failure (SPOF) are deadly
- âœ… Core services (like DNS, DynamoDB) need multi-region redundancy
- âœ… Dependent services should have graceful degradation modes

#### 4ï¸âƒ£ "Congestion Collapse" During Recovery

DWFM's problem:
```
Lease timeout â†’ retry â†’ task accumulation â†’ slower processing â†’ lease timeout again â†’ more retries
```

This is a typical positive feedback loop - the busier the system gets, the slower it becomes; the slower it becomes, the busier it gets.

SRE Solutions:
- âœ… Rate Limiting: Control retry rates
- âœ… Backpressure: Dynamically adjust based on queue length
- âœ… Circuit Breaker: Pause retries when anomalies detected

#### 5ï¸âƒ£ Monitoring and Alerting Blind Spots

- DNS problem occurred at 23:48, but root cause wasn't identified until 00:38 (50 minutes)
- NLB health check issues started at 05:30, but weren't detected by monitoring until 06:52 (82 minutes)

SRE Principles:
- âš ï¸ You can't fix what you can't see
- âœ… Need end-to-end health checks, not just component-level monitoring
- âœ… Synthetic Monitoring: Simulate real user requests

#### 6ï¸âƒ£ Insufficient Test Coverage

AWS admitted:
> "There was no established operational recovery procedure for this situation"

SRE Practices:
- âœ… Chaos Engineering: Actively inject failures to test system resilience
- âœ… Disaster Recovery Drills: Regularly simulate large-scale failures
- âœ… Game Days: Team collaborative failure response exercises

### ðŸ› ï¸ AWS's Improvement Measures

1. Immediate Actions:
   - âœ… Globally disabled DNS automation system (stop the bleeding first)
   - âœ… Fixed the race condition
   - âœ… Added safeguards to prevent applying incorrect plans

2. Medium-term Improvements:
   - âœ… Added rate controls to NLB, limiting capacity removed in single failover
   - âœ… Built test suites for EC2 DWFM recovery procedures
   - âœ… Improved rate limiting mechanisms for data synchronization systems

3. Long-term Optimizations:
   - âœ… Deep analysis of all affected services
   - âœ… Identify methods to avoid similar incidents
   - âœ… Reduce recovery time

### ðŸŽ¯ Summary

This incident is a classic distributed system race condition case, exposing several key issues:

1. Danger of time assumptions: TOCTOU (Time-of-Check to Time-of-Use) problem
2. Power of cascading failures: One DNS issue caused multiple services across entire region to fail
3. Complexity of recovery process: Congestion collapse, positive feedback loops
4. Importance of test coverage: Recovery procedures never rehearsed will be chaotic during real failures

Most Important Lesson:
> In distributed systems, never trust "outdated check results." Always re-verify preconditions before each critical operation.

This is like driving through an intersection: even if you see a green light, you should confirm again before entering the intersection that no cars are running the red light. In distributed systems, this "double-check" mechanism can prevent many catastrophic failures.
