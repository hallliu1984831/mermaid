----- Chinese
# GPUËá™Áî±‰∫ÜÔºüÂà´ÊÄ•ÁùÄÂºÄÈ¶ôÊßü

## üìã Áé∞Áä∂Ê¶ÇËßà

2025Âπ¥11Êúà2Êó•ÔºåÂæÆËΩØCEOÁ∫≥Âæ∑ÊãâÁàÜÂá∫"ÂØå‰∫∫ÁÉ¶ÊÅº"ÔºöÊàëÊúâ‰∏ÄÂ†ÜGPUÔºå‰ΩÜÊòØÊèí‰∏ç‰∏äÁîµÔºÅ ËøôÊè≠Á§∫‰∫ÜAIÊó∂‰ª£ÁöÑÊ∑±ÂàªÁüõÁõæ‚Äî‚ÄîÊäÄÊúØÂèëÂ±ïÈÄüÂ∫¶ËøúË∂ÖÂü∫Á°ÄËÆæÊñΩÂª∫ËÆæÊ≠•‰ºê„ÄÇÂ∞±Â•ΩÊØî‰Ω†‰π∞‰∫Ü100ËæÜÁâπÊñØÊãâÔºåÂèëÁé∞Â∞èÂå∫Âè™Êúâ2‰∏™ÂÖÖÁîµÊ°©üòÇ

## ‰∏Ä„ÄÅÂæÆËΩØCEOÁöÑ"ÁîúËúúÁÉ¶ÊÅº"
Á∫≥Âæ∑ÊãâÂéüËØùÔºö
"I think the cycles of demand and supply in this particular case, you can't really predict, right? The point is: what's the secular trend? The secular trend is what Sam (OpenAI CEO) said, which is, at the end of the day, because quite frankly, the biggest issue we are now having is not a compute glut, but it's power ‚Äî it's sort of the ability to get the builds done fast enough close to power. So, if you can't do that, you may actually have a bunch of chips sitting in inventory that I can't plug in. In fact, that is my problem today. It's not a supply issue of chips; it's actually the fact that I don't have warm shells to plug into."
ÁÆÄÂçïÊù•ËØ¥ÔºöÊàë‰∏çÁº∫ÁÆóÂäõÔºàÂú®‰ªìÂ∫ìÈáåË∫∫ÁùÄÂëêÔºâÔºåÊàëÁº∫ÁöÑÊòØÁîµÂäõ‚ö°Ô∏è
"Warm Shells" = ÈÖçÂ§á‰∫ÜÁîµÂäõ„ÄÅÊ∞¥Ê∫êÁöÑÁ©∫Êï∞ÊçÆ‰∏≠ÂøÉÂª∫Á≠ëÔºàÁ≤æË£ÖÊàøÔºåÊ∞¥ÁîµÈΩêÂÖ®ÔºåÊãéÂåÖÂÖ•‰ΩèÔºâ
ÈóÆÈ¢òÊ†∏ÂøÉÔºöÂæÆËΩØÊúâÈí±‰π∞GPUÔºàÂÆ∂ÂÖ∑ÔºâÔºå‰ΩÜÊ≤°ÊúâË∂≥Â§üÁöÑÁ≤æË£ÖÊàøÊù•ÊîæÁΩÆÔºÅ

## ‰∫å„ÄÅGPUÂØåÁøÅÁöÑÁúüÂÆûÂõ∞Â¢ÉÔºöÊúâÈí±‰πü‰ªªÊÄß‰∏ç‰∫Ü

### üî• AIËÆ≠ÁªÉÁöÑÁîµËÄÅËôéÊú¨Ë¥®
ËÆ©Êàë‰ª¨Áî®‰∏Ä‰∫õÁõ¥ËßÇÁöÑÊï∞Â≠óÊù•ÊÑüÂèó‰∏Ä‰∏ãAIËÆ≠ÁªÉÂà∞Â∫ïÊúâÂ§öËÄóÁîµÔºö
‰∏ÄÂè∞È´òÁ´ØAIÊúçÂä°Âô®ÁöÑËÄóÁîµÈáèÔºö
8Âº†H100 GPU = Á∫¶5.6kWÔºàÁõ∏ÂΩì‰∫é5-6Âè∞Á©∫Ë∞ÉÂêåÊó∂ËøêË°åÔºâ
‰∏Ä‰∏™Ê†áÂáÜÊú∫Êû∂8-12Âè∞ÊúçÂä°Âô® = Á∫¶45-70kW
‰∏Ä‰∏™Â§ßÂûãAIÊï∞ÊçÆ‰∏≠ÂøÉ = 50-200MWÔºàÁõ∏ÂΩì‰∫é‰∏Ä‰∏™‰∏≠Â∞èÂüéÂ∏ÇÁöÑÁû¨Êó∂Áî®ÁîµÂäüÁéáÔºâ

Êç¢‰∏™ËßíÂ∫¶ÁêÜËß£Ôºö
ËÆ≠ÁªÉ‰∏Ä‰∏™Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã ‚âà Ê∂àËÄó10-50 GWhÁîµÂäõÔºàÁõ∏ÂΩì‰∫éÂá†ÂçÉÊà∑ÂÆ∂Â∫≠‰∏ÄÂπ¥ÁöÑÁî®ÁîµÈáèÔºâ
ËøêË°åChatGPT‰∏ÄÂ§© ‚âà Á∫¶50-100 MWhÔºàÁõ∏ÂΩì‰∫é1500-3000Êà∑ÂÆ∂Â∫≠‰∏ÄÂ§©ÁöÑÁî®ÁîµÈáèÔºâ
ÂæÆËΩØÁöÑAIÊï∞ÊçÆ‰∏≠ÂøÉ ‚âà ÊåÅÁª≠ÂäüÁéáÈúÄÊ±ÇÊï∞GWÁ∫ßÂà´ÔºàÁõ∏ÂΩì‰∫éÂá†‰∏™‰∏≠Â∞èÂüéÂ∏ÇÁöÑÊÄªÁî®ÁîµÂäüÁéáÔºâ

### ‚ö° ÁîµÂäõÈúÄÊ±Ç vs ‰æõÂ∫îÁöÑÊó∂Èó¥ÈîôÈÖç
ËøôÂ∞±ÊòØÈóÆÈ¢òÁöÑÊ†∏ÂøÉÔºöÈúÄÊ±ÇÁàÜÂèëÁöÑÈÄüÂ∫¶ >> Âü∫Á°ÄËÆæÊñΩÂª∫ËÆæÁöÑÈÄüÂ∫¶
Êó∂Èó¥Á∫øÂØπÊØîÔºö
‰π∞GPUÔºöÂá†‰∏™ÊúàÔºàÊúâÈí±Â∞±Ë°åÔºâ
Âª∫Êï∞ÊçÆ‰∏≠ÂøÉÔºö2-3Âπ¥ÔºàÈúÄË¶ÅËßÑÂàí„ÄÅÂÆ°Êâπ„ÄÅÂª∫ËÆæÔºâ
Âª∫ÂèëÁîµÂéÇÔºö5-10Âπ¥ÔºàËøòË¶ÅÁéØËØÑ„ÄÅÈÄâÂùÄ„ÄÅÊäÄÊúØËÆ∫ËØÅÔºâ

### üèóÔ∏è Âü∫Á°ÄËÆæÊñΩ"‰∏âÈáçÈó®"
ÁîµÂäõ‰æõÂ∫îÔºöÈúÄË¶ÅÁ®≥ÂÆöÂ§ßÂÆπÈáèÁîµÊ∫êÔºå‰º†ÁªüÁîµÁΩëÈöæÊâøÂèóÂ∑®Â§ßË¥üËç∑
ÂÜ∑Âç¥Á≥ªÁªüÔºöGPUÂèëÁÉ≠Â∑®Â§ßÔºåÂÜ∑Âç¥ËÄóÁîµ30-50%
ÁΩëÁªúËøûÊé•ÔºöË∂ÖÈ´òÈÄü„ÄÅ‰ΩéÂª∂Ëøü„ÄÅÂ§ßÂ∏¶ÂÆΩÈúÄÊ±Ç


## ‰∏â„ÄÅÊï∞ÊçÆ‰∏≠ÂøÉÔºöÁé∞‰ª£Áâà"ÁîµËÄÅËôé"

### üêÖ ÂÖ®ÁêÉAIÊï∞ÊçÆ‰∏≠ÂøÉËÄóÁîµÊÉÖÂÜµ
ÂØπÊØî‰º†ÁªüÁöÑITÊï∞ÊçÆ‰∏≠ÂøÉÔºåAIÊï∞ÊçÆ‰∏≠ÂøÉÁöÑËÄóÁîµÈáèÊòØÂÖ∂3-5ÂÄç
ÂæÆËΩØ2024Âπ¥ÔºöAIÈÉ®ÁΩ≤ÂØºËá¥ËÉΩÊ∫êÊ∂àËÄóÊòæËëóÂ¢ûÈïø
Ë∞∑Ê≠å2024Âπ¥ÔºöÂπ¥ËÄóÁîµÁ∫¶18-20 TWhÔºàÁõ∏ÂΩì‰∫é‰∏πÈ∫¶ÂÖ®ÂõΩÁî®ÁîµÈáèÔºâ
ChatGPTÔºöÊó•ËÄóÁîµÈáèÁ∫¶50-100 MWh

üîå AI‰∏∫‰ªÄ‰πàËøô‰πàËÄóÁîµÔºü
ÂäüËÄóÂØπÊØîÔºö
ÊâãÊú∫ÂÖÖÁîµÔºö5-10W | Á¨îËÆ∞Êú¨Ôºö50-100W | Á©∫Ë∞ÉÔºö1000-3000W
ÂçïÂº†H100 GPUÔºö700WÔºàÁõ∏ÂΩì‰∫éÂ§ßÁ©∫Ë∞ÉÔºâ

ËßÑÊ®°ÊïàÂ∫îÔºö
AIÈõÜÁæ§ÔºöÂá†ÂçÉÂà∞Âá†‰∏áÂº†GPUÔºå24Â∞èÊó∂ËøêË°å
Â§ßÊ®°ÂûãËÆ≠ÁªÉÔºöÂá†‰∏™ÊúàÂà∞‰∏ÄÂπ¥Ôºå‰∏çËÉΩ‰∏≠Êñ≠

Êï£ÁÉ≠ÈóÆÈ¢òÔºö
Âá†ÂçÉÂº†GPUÁÉ≠Èáè ‚âà Â∞èÂûãÈí¢ÈìÅÂéÇ
ÂÜ∑Âç¥Á≥ªÁªüËÄóÁîµ ‚âà GPUÊú¨Ë∫´ËÄóÁîµÁöÑ30-50%
Âõ†Ê≠§AIÂÖ¨Âè∏ÈÄâÊã©ÂåóÊ¨ß„ÄÅÂÜ∞Â≤õ„ÄÅÂä†ÊãøÂ§ßÁ≠âÂØíÂÜ∑Âú∞Âå∫Âª∫Êï∞ÊçÆ‰∏≠ÂøÉ

## Âõõ„ÄÅÊó∂Èó¥Â∞±ÊòØÈáëÈí±ÔºöGPUÁöÑ"‰øùË¥®Êúü"ÁÑ¶Ëôë

### üí∏ ‰ªìÂ∫ìÈáåÁöÑGPUÔºöÊòÇË¥µÁöÑ"ÁîµÂ≠êÂûÉÂúæ"
ÊÉ≥Ë±°‰∏Ä‰∏ãËøô‰∏™Âú∫ÊôØÔºö‰Ω†Ëä±‰∫ÜÈ´ò‰ª∑‰π∞‰∫ÜÊúÄÊñ∞Ê¨æÁöÑË∂ÖÁ∫ßË∑ëËΩ¶ÔºåÁªìÊûúÂè™ËÉΩÊîæÂú®ËΩ¶Â∫ìÈáåÂêÉÁÅ∞„ÄÇÊõ¥Ë¶ÅÂëΩÁöÑÊòØÔºåÊØèËøá‰∏ÄÂ§©ÔºåËøô‰∫õË∑ëËΩ¶Â∞±Ë¥¨ÂÄº‰∏ÄÁÇπÔºåËÄå‰Ω†Âç¥Âè™ËÉΩÁúºÁùÅÁùÅÂú∞ÁúãÁùÄÔºÅ

ËøôÂ∞±ÊòØÂæÆËΩØÁ≠âAIÂ∑®Â§¥Áé∞Âú®Èù¢‰∏¥ÁöÑÊÆãÈÖ∑Áé∞ÂÆûÔºö
H100 GPUÂçï‰ª∑ÔºöÁ∫¶2-4‰∏áÁæéÂÖÉ
Â∫ìÂ≠òËßÑÊ®°ÔºöÊàêÂçÉ‰∏ä‰∏áÂº†
ÊØèÊó•ÊäòÊóßÔºöÊåâ3Âπ¥ÊäòÊóßËÆ°ÁÆóÔºåÊØèÂº†GPUÊØèÂ§©Ë¥¨ÂÄºÁ∫¶20-40ÁæéÂÖÉ
ÊÄªÊçüÂ§±ÔºöÊØèÂ§©ÂèØËÉΩÊçüÂ§±Êï∞ÂçÅ‰∏áÂà∞Êï∞Áôæ‰∏áÁæéÂÖÉ

‚è∞ ÁßëÊäÄ‰∫ßÂìÅÁöÑ"ÁâõÂ•∂ÂÆöÂæã"
Âú®ÁßëÊäÄË°å‰∏öÔºåÊúâ‰∏Ä‰∏™ÊÆãÈÖ∑ÁöÑÂÆöÂæãÔºöÁ°¨‰ª∂ÁöÑ‰ª∑ÂÄºÈöèÊó∂Èó¥ÊåáÊï∞Á∫ßË°∞Âáè„ÄÇ
GPU‰ª∑ÂÄºË°∞ÂáèÊó∂Èó¥Á∫øÔºö
ÂèëÂ∏ÉÊó∂Ôºö100%‰ª∑ÂÄºÔºàÊúÄÊñ∞ÊúÄÂº∫Ôºâ
6‰∏™ÊúàÂêéÔºö80%‰ª∑ÂÄºÔºàÊñ∞‰∏Ä‰ª£‰∫ßÂìÅÂèëÂ∏ÉÈ¢ÑÂëäÔºâ
1Âπ¥ÂêéÔºö60%‰ª∑ÂÄºÔºàÊñ∞‰∫ßÂìÅÊ≠£ÂºèÂèëÂ∏ÉÔºâ
2Âπ¥ÂêéÔºö40%‰ª∑ÂÄºÔºàÊÄßËÉΩË¢´Ë∂ÖË∂äÔºâ
3Âπ¥ÂêéÔºö20%‰ª∑ÂÄºÔºàÂü∫Êú¨Ê∑òÊ±∞Ôºâ

üèÉ‚Äç‚ôÇÔ∏è Êë©Â∞îÂÆöÂæãÁöÑ"ËøΩÊùÄ"
ÊäÄÊúØËø≠‰ª£ÁöÑÊÅêÊÄñÈÄüÂ∫¶
Ëã±‰ºüËææÂèëÂ∏ÉÂë®ÊúüÔºöÁ∫¶2Âπ¥‰∏Ä‰ª£
ÊÄßËÉΩÊèêÂçáÂπÖÂ∫¶ÔºöÊØè‰ª£ÊèêÂçá50-100%
ËÉΩÊïàÊØîÊîπËøõÔºöÊØè‰ª£ÊèêÂçá30-50%

Áé∞ÂÆûÊ°à‰æãÔºö
2022Âπ¥ÔºöA100ÊòØÁéãËÄÖ
2023Âπ¥ÔºöH100Ê®™Á©∫Âá∫‰∏ñÔºåA100Áû¨Èó¥"ËøáÊ∞î"
2024Âπ¥ÔºöH200„ÄÅB100ËìÑÂäøÂæÖÂèë
2025Âπ¥Ôºö‰∏ã‰∏Ä‰ª£Êû∂ÊûÑÂ∑≤Âú®Ë∑Ø‰∏ä

üí∞ Âõ§ÁßØÊàêÊú¨ÁöÑÈöêÂΩ¢ÊùÄÊâã
Â¶Ç‰∏äÊâÄËø∞ÁöÑÁõ¥Êé•ÊäòÊóßÊàêÊú¨

Êú∫‰ºöÊàêÊú¨
ËµÑÈáëÂç†Áî®Ôºö3‰∫øÁæéÂÖÉÁöÑËµÑÈáëÊàêÊú¨
Á´û‰∫âÂä£ÂäøÔºöÁ´û‰∫âÂØπÊâãÂú®Áî®Êñ∞ÊäÄÊúØËÆ≠ÁªÉÊ®°Âûã
Â∏ÇÂú∫‰ªΩÈ¢ùÔºöÈîôËøáAIÂèëÂ±ïÁöÑÈªÑÈáëÁ™óÂè£

Áª¥Êä§ÊàêÊú¨
‰ªìÂÇ®Ë¥πÁî®Ôºö‰∏ì‰∏öÂ≠òÂÇ®ÁéØÂ¢É
‰øùÈô©Ë¥πÁî®ÔºöÈ´ò‰ª∑ÂÄºËÆæÂ§á‰øùÈô©
ÁÆ°ÁêÜÊàêÊú¨ÔºöÂ∫ìÂ≠òÁÆ°ÁêÜ‰∫∫Âëò

### üéØ ‰∏∫‰ªÄ‰πà‰∏çËÉΩÁ≠âÁ≠âÂÜç‰π∞Ôºü
‰Ω†ÂèØËÉΩ‰ºöÈóÆÔºöÊó¢ÁÑ∂‰ºöË¥¨ÂÄºÔºå‰∏∫‰ªÄ‰πà‰∏çÁ≠âÁîµÂäõÂü∫Á°ÄËÆæÊñΩÂáÜÂ§áÂ•ΩÂÜç‰π∞GPUÔºü
Áé∞ÂÆûÂæàÊÆãÈÖ∑Ôºö
Á´û‰∫âÂéãÂäõÔºöÁ´û‰∫âÂØπÊâã‰∏ç‰ºöÁ≠â‰Ω†
‰æõÂ∫îÈìæÈ£éÈô©ÔºöGPUÂèØËÉΩÊñ≠Ë¥ßÊàñÊ∂®‰ª∑
È°πÁõÆÊó∂Èó¥Á∫øÔºöAIÈ°πÁõÆÊúâ‰∏•Ê†ºÁöÑÊó∂Èó¥Ë¶ÅÊ±Ç
ÊäïËµÑËÄÖÊúüÊúõÔºöËÇ°‰∏ú‰∏ç‰ºöÊé•Âèó"Á≠âÁ≠âÁúã"ÁöÑÁ≠ñÁï•
Â¶ÇÊûúÈîôËøáAIÂèëÂ±ïÁ™óÂè£ÔºåÂ∞±ÂèØËÉΩË¢´Á´û‰∫âÂØπÊâãËøúËøúÁî©Âú®Ë∫´ÂêéÔºå‰∏ÄÊ≠•ËêΩÂêéÂ∞±ÂæàÈöæÂÜçËøΩ‰∏ä‰∫Ü„ÄÇ


## ‰∫î„ÄÅËß£ÂÜ≥ÊñπÊ°àÔºö‰ªé"ÂºÄÊ∫ê"Âà∞"ËäÇÊµÅ"

### üîã ÂºÄÊ∫êÔºöÂØªÊâæÊõ¥Â§öÁîµÂäõ

#### Ê†∏ÁîµÂ§çÂÖ¥ÔºöÂæÆËΩØÁöÑ"Ê†∏"ÂøÉÁ≠ñÁï•
2024Âπ¥9Êúà20Êó•ÔºåÂæÆËΩØ‰∏éConstellation EnergyÁ≠æÁΩ≤ÂçèËÆÆÔºåÈáçÂêØ‰∏âÈáåÂ≤õÊ†∏ÁîµÁ´ôÔºö
20Âπ¥ÁîµÂäõÈááË¥≠ÂçèËÆÆ
È¢ÑËÆ°2028Âπ¥Êäï‰∫ß
‰∏ìÈó®‰∏∫AIÊï∞ÊçÆ‰∏≠ÂøÉ‰æõÁîµ
ËøôÂ∞±ÂÉèÊòØÁªôËá™Â∑±ÁöÑAIÂ∏ùÂõΩÂª∫‰∫Ü‰∏Ä‰∏™‰∏ìÂ±ûÂèëÁîµÂéÇÔºÅ‰ΩÜÊòØÔºå2024Âπ¥9ÊúàÁ≠æÂçèËÆÆ ‚Üí 2025Âπ¥11ÊúàËøòÂú®Á≠âÁîµ ‚Üí 2028Âπ¥ÊâçËÉΩÁî®‰∏ä

#### ÂèØÂÜçÁîüËÉΩÊ∫ê+ÂÇ®ËÉΩ
Â§™Èò≥ËÉΩ+È£éËÉΩÔºöÁôΩÂ§©Áî®Â§™Èò≥ËÉΩÔºåÊôö‰∏äÁî®È£éËÉΩ
Â§ßÂûãÂÇ®ËÉΩÁ≥ªÁªüÔºöÊääÂ§ö‰ΩôÁöÑÁîµÂ≠òËµ∑Êù•
Êô∫ËÉΩË∞ÉÂ∫¶ÔºöÊ†πÊçÆÁîµ‰ª∑Âíå‰æõÂ∫îÊÉÖÂÜµË∞ÉÊï¥ËÆ≠ÁªÉÊó∂Èó¥

### ‚ö° ËäÇÊµÅÔºöÊèêÈ´òËÉΩÊïà

#### Á°¨‰ª∂‰ºòÂåñ
Êõ¥È´òÊïàÁöÑGPUÔºöÂêåÊ†∑ÁÆóÂäõÔºåÊõ¥‰ΩéÂäüËÄó
Ê∂≤ÂÜ∑ÊäÄÊúØÔºöÊØîÈ£éÂÜ∑ËäÇËÉΩ30-50%
Ê®°ÂùóÂåñËÆæËÆ°ÔºöÊåâÈúÄÊâ©Â±ïÔºåÈÅøÂÖçÊµ™Ë¥π

#### ËΩØ‰ª∂‰ºòÂåñ
Ê®°ÂûãÂéãÁº©ÔºöÁî®Êõ¥Â∞èÁöÑÊ®°ÂûãËææÂà∞Á±ª‰ººÊïàÊûú
ÂàÜÂ∏ÉÂºèËÆ≠ÁªÉÔºöÊää‰ªªÂä°ÂàÜÊï£Âà∞Â§ö‰∏™Âú∞ÁÇπ
Êô∫ËÉΩË∞ÉÂ∫¶ÔºöÂú®Áîµ‰ª∑‰ΩéÁöÑÊó∂ÂÄôËÆ≠ÁªÉ

#### Êû∂ÊûÑÂàõÊñ∞
ËæπÁºòËÆ°ÁÆóÔºöÊääËÆ°ÁÆóÂàÜÊï£Âà∞Áî®Êà∑ÈôÑËøë
Ê∑∑Âêà‰∫ëÔºöÂú®‰∏çÂêåÂú∞Âå∫ÁöÑÊï∞ÊçÆ‰∏≠ÂøÉÈó¥Ë∞ÉÂ∫¶
‰∏ìÁî®ËäØÁâáÔºö‰∏∫ÁâπÂÆö‰ªªÂä°ËÆæËÆ°ÁöÑ‰ΩéÂäüËÄóËäØÁâá


## ÂÖ≠„ÄÅÁªôSREÂíåÊäÄÊúØ‰∫∫ÂëòÁöÑÂêØÁ§∫

### üí° ÂÆπÈáèËßÑÂàíÁöÑÊñ∞Áª¥Â∫¶
‰º†ÁªüÁöÑÂÆπÈáèËßÑÂàíËÄÉËôëÔºöCPU„ÄÅÂÜÖÂ≠ò„ÄÅÂ≠òÂÇ®„ÄÅÁΩëÁªú
AIÊó∂‰ª£ËøòË¶ÅËÄÉËôëÔºöÁîµÂäõ„ÄÅÂÜ∑Âç¥„ÄÅÁ¢≥ÊéíÊîæ

### üéØ ËÅå‰∏öÂèëÂ±ïÊñ∞ÊñπÂêë
Êñ∞ÂûãÁîµÂäõÂ∑•Á®ãÂ∏àÔºö‰ºòÂåñAIÁ≥ªÁªüÁöÑËÉΩËÄó
Êï∞ÊçÆ‰∏≠ÂøÉËÉΩÊïàÂ∑•Á®ãÂ∏àÔºöËÆæËÆ°È´òÊïàÁöÑÂÜ∑Âç¥Âíå‰æõÁîµÁ≥ªÁªü
ÂèØÊåÅÁª≠ÊÄßSREÔºöÂπ≥Ë°°ÊÄßËÉΩ‰∏éÁéØ‰øù

### üõ†Ô∏è ÊäÄÊúØÈÄâÂûãÊñ∞ËÄÉÈáè
ÈÄâÊã©ÊäÄÊúØÊñπÊ°àÊó∂ÔºåÈô§‰∫ÜÂäüËÉΩÂíåÊÄßËÉΩÔºåËøòË¶ÅËÄÉËôëÔºö
ËÉΩËÄóÊØîÔºöÊØèÁì¶ÁâπËÉΩÊèê‰æõÂ§öÂ∞ëÁÆóÂäõ
ÁÉ≠ËÆæËÆ°ÂäüËÄóÔºöÂØπÂÜ∑Âç¥Á≥ªÁªüÁöÑË¶ÅÊ±Ç
ÂèØÊâ©Â±ïÊÄßÔºöËÉΩÂê¶Ê†πÊçÆÁîµÂäõ‰æõÂ∫îÁÅµÊ¥ªË∞ÉÊï¥



## üéØ ÊÄªÁªìÔºöGPUÂØåÁøÅÁöÑÁîúËúúÁÉ¶ÊÅº
ÂæÆËΩØCEOÁöÑ"ÁîúËúúÁÉ¶ÊÅº"Êè≠Á§∫‰∫ÜAIÊó∂‰ª£ÁöÑ‰∏Ä‰∏™Ê∑±ÂàªÁüõÁõæÔºöÊäÄÊúØËøõÊ≠•ÁöÑÈÄüÂ∫¶ËøúË∂ÖÂü∫Á°ÄËÆæÊñΩÂª∫ËÆæÁöÑÊ≠•‰ºê„ÄÇÂú®AIÊó∂‰ª£ÔºåÊã•ÊúâÊúÄÂÖàËøõÁöÑÁ°¨‰ª∂Âè™ÊòØÊàêÂäüÁöÑÁ¨¨‰∏ÄÊ≠•„ÄÇÁúüÊ≠£ÁöÑÁ´û‰∫â‰ºòÂäøÂú®‰∫éËÉΩÂê¶ÊûÑÂª∫ÂÆåÊï¥ÁöÑÂü∫Á°ÄËÆæÊñΩÁîüÊÄÅÁ≥ªÁªü„ÄÇ

ËøôÊèêÈÜíÊàë‰ª¨ÔºöÊäÄÊúØÂèëÂ±ï‰∏ç‰ªÖ‰ªÖÊòØÁÆóÊ≥ïÂíåÁ°¨‰ª∂ÁöÑÁ´ûËµõÔºåÊõ¥ÊòØÂü∫Á°ÄËÆæÊñΩÂíåËµÑÊ∫êÈÖçÁΩÆÁöÑÁ´ûËµõ„ÄÇÂú®AIÁöÑ‰∏ñÁïåÈáåÔºåÁîµÂäõÂ∞±ÊòØÊñ∞ÁöÑÁü≥Ê≤πÔºåÊï∞ÊçÆ‰∏≠ÂøÉÂ∞±ÊòØÊñ∞ÁöÑÁÇºÊ≤πÂéÇÔºÅ

Êú™Êù•ÁöÑAIÂ∑®Â§¥Ôºå‰∏ç‰ªÖË¶Å‰ºöÂÜô‰ª£Á†Å„ÄÅËÆæËÆ°ËäØÁâáÔºåËøòË¶Å‰ºöÂª∫ÁîµÂéÇ„ÄÅÁÆ°ÁîµÁΩë„ÄÅ‰ºòÂåñËÉΩËÄó„ÄÇËøôÊâçÊòØÁúüÊ≠£ÁöÑ"ÂÖ®Ê†à"Â∑•Á®ãÂ∏àÔºÅüöÄ



----- English
# Got GPUs? Don't Pop the Champagne Yet!

## üìã Current Situation Overview

On November 2, 2025, Microsoft CEO Nadella revealed a "rich people problem": I have tons of GPUs, but nowhere to plug them in! This exposes AI era's profound contradiction‚Äîtech development speed far outpaces infrastructure construction. It's like buying 100 Teslas only to find your neighborhood has 2 charging stationsüòÇ

## 1. Microsoft CEO's "Sweet Burden"

Nadella's exact words:
> "I think the cycles of demand and supply in this particular case, you can't really predict, right? The point is: what's the secular trend? The secular trend is what Sam (OpenAI CEO) said, which is, at the end of the day, because quite frankly, the biggest issue we are now having is not a compute glut, but it's power ‚Äî it's sort of the ability to get the builds done fast enough close to power. So, if you can't do that, you may actually have a bunch of chips sitting in inventory that I can't plug in. In fact, that is my problem today. It's not a supply issue of chips; it's actually the fact that I don't have warm shells to plug into."

Simply put: I don't lack computing power (sitting in warehouses), I lack electricity‚ö°Ô∏è

"Warm Shells" = Empty data center buildings with power and water infrastructure (move-in ready buildings)

Core problem: Microsoft can buy GPUs (furniture) but lacks enough move-in ready buildings!

## 2. GPU Millionaires' Real Dilemma: Money Can't Buy Everything

### üî• The Power-Hungry Nature of AI Training

Let's use some intuitive numbers to understand just how power-hungry AI training really is:

```
High-end AI server power consumption:
- 8 H100 GPUs = ~5.6kW (equivalent to 5-6 air conditioners running simultaneously)
- One standard rack with 8-12 servers = ~45-70kW
- One large AI data center = 50-200MW (equivalent to a small-to-medium city's instantaneous power demand)
```

From another perspective:
- Training a large language model ‚âà Consuming 10-50 GWh of electricity (equivalent to thousands of households' annual electricity consumption)
- Running ChatGPT for one day ‚âà ~50-100 MWh (equivalent to 1500-3000 households' daily electricity consumption)
- Microsoft's AI data centers ‚âà Multi-GW continuous power demand (equivalent to several small-to-medium cities' total power consumption)

### ‚ö° Power Demand vs Supply Time Mismatch

This is the core of the problem: Demand explosion speed >> Infrastructure construction speed

```
Timeline comparison:
Buying GPUs: A few months (money talks)
Building data centers: 2-3 years (planning, approval, construction required)
Building power plants: 5-10 years (environmental assessment, site selection, technical validation needed)
```

### üèóÔ∏è Infrastructure "Triple Gate"
1. Power Supply: Requires stable, high-capacity power sources, traditional grids struggle with massive loads
2. Cooling Systems: GPUs generate enormous heat, cooling consumes 30-50% power
3. Network Connectivity: Ultra-high-speed, low-latency, massive bandwidth requirements

## 3. Data Centers: Modern "Power Monsters"

### üêÖ Global AI Data Center Power Consumption
AI data centers: 3-5x more power-hungry than traditional data centers
- Microsoft 2024: Significant energy consumption increases due to AI deployment
- Google 2024: Annual consumption ~18-20 TWh (equivalent to Denmark's national consumption)
- ChatGPT: Daily consumption ~50-100 MWh

### üîå Why Is AI So Power-Hungry?

#### 1. GPUs Are Inherently Power Monsters
```
Compare daily device power consumption:
- Phone charging: 5-10W
- Laptop: 50-100W
- Home air conditioner: 1000-3000W
- Single H100 GPU: 700W (equivalent to a large AC unit)
```

#### 2. The Terror of Scale
- An AI cluster: Thousands to tens of thousands of GPUs
- 24/7 non-stop operation
- Plus supporting equipment for cooling, networking, storage

#### 3. Training Time Costs
- Large model training: Several months to a year
- Cannot be interrupted (interruption means starting over)
- Requires redundant backups (to prevent hardware failures)

### üå°Ô∏è Heat Dissipation: Another Major Challenge

GPUs don't just consume power‚Äîthey generate heat:
- One H100 GPU heat output ‚âà A small space heater
- Thousands of GPUs together ‚âà Heat output of a small steel mill
- Cooling system power consumption ‚âà 30-50% of GPU power consumption

This is why many AI companies build data centers in:
- Nordic countries: Natural cooling, lower electricity costs
- Iceland: Geothermal power + natural cooling
- Canada: Cheap hydroelectric power + cold climate

## 4. Time Is Money: GPU "Expiration Date" Anxiety

### üí∏ GPUs in Warehouses: Expensive "Electronic Waste"

Imagine this scenario: You spent high prices on the latest supercars, only to have them collect dust in your garage. Worse yet, every day that passes, these cars depreciate a little more, and you can only watch helplessly!

This is the brutal reality facing AI giants like Microsoft:
- H100 GPU unit price: ~$20,000-40,000
- Inventory scale: Thousands upon thousands of units
- Daily depreciation: Based on 3-year depreciation, each GPU loses ~$20-40 in value daily
- Total losses: Potentially hundreds of thousands to millions of dollars lost daily

### ‚è∞ The "Milk Law" of Tech Products

In the tech industry, there's a brutal law: Hardware value decays exponentially over time.

```
GPU Value Depreciation Timeline:
At launch: 100% value (newest and strongest)
6 months later: 80% value (next-gen product announcements)
1 year later: 60% value (new products officially released)
2 years later: 40% value (performance surpassed)
3 years later: 20% value (essentially obsolete)
```

### üèÉ‚Äç‚ôÇÔ∏è Moore's Law "Pursuit"

Terrifying speed of technological iteration:
- NVIDIA release cycle: ~2 years per generation
- Performance improvement: 50-100% per generation
- Energy efficiency improvement: 30-50% per generation

Real-world example:
- 2022: A100 was king
- 2023: H100 emerged, A100 instantly "outdated"
- 2024: H200, B100 waiting in the wings
- 2025: Next-gen architecture already in development

### üí∞ Hidden Killers of Hoarding Costs

#### Direct depreciation costs
As mentioned above

#### Opportunity costs
- Capital tie-up: $300 million in capital costs
- Competitive disadvantage: Competitors using new tech to train models
- Market share: Missing the golden window of AI development

#### Maintenance costs
- Storage fees: Professional storage environment
- Insurance costs: High-value equipment insurance
- Management costs: Inventory management personnel

### üéØ Why Not Wait Before Buying?

You might ask: If they depreciate, why not wait until power infrastructure is ready before buying GPUs?

Reality is brutal:
- Competitive pressure: Competitors won't wait for you
- Supply chain risks: GPUs might go out of stock or increase in price
- Project timelines: AI projects have strict time requirements
- Investor expectations: Shareholders won't accept a "wait and see" strategy

If you miss the AI development window, you might be left far behind by competitors, and once you fall behind, it's very difficult to catch up.

## 5. Solutions: From "Increasing Supply" to "Reducing Demand"

### üîã Increasing Supply: Finding More Power

#### Nuclear Revival: Microsoft's "Nuclear" Strategy
On September 20, 2024, Microsoft signed an agreement with Constellation Energy to restart Three Mile Island:
- 20-year power purchase agreement
- Expected operational by 2028
- Dedicated to powering AI data centers

It's like building a dedicated power plant for your AI empire! But: September 2024 agreement ‚Üí November 2025 still waiting for power ‚Üí 2028 finally available

#### Renewables + Storage
- Solar + Wind: Solar during day, wind at night
- Large-scale storage systems: Store excess electricity
- Smart scheduling: Adjust training times based on electricity prices and supply

### ‚ö° Reducing Demand: Improving Efficiency

#### Hardware Optimization
- More efficient GPUs: Same computing power, lower consumption
- Liquid cooling: 30-50% more energy-efficient than air cooling
- Modular design: Scale on-demand, avoid waste

#### Software Optimization
- Model compression: Achieve similar results with smaller models
- Distributed training: Spread tasks across multiple locations
- Smart scheduling: Train during low electricity price periods

#### Architectural Innovation
- Edge computing: Distribute computing closer to users
- Hybrid cloud: Schedule across data centers in different regions
- Specialized chips: Low-power chips designed for specific tasks

## 6. Insights for SREs and Technical Professionals

### üí° New Dimensions in Capacity Planning
Traditional capacity planning considers: CPU, memory, storage, network
AI era also requires: Power, cooling, carbon emissions

### üéØ New Career Development Directions
- New-type electrical engineers: Optimize AI system energy consumption
- Data center energy efficiency engineers: Design efficient cooling and power supply systems
- Sustainability SREs: Balance performance with environmental protection

### üõ†Ô∏è New Considerations in Technology Selection
When choosing technical solutions, beyond functionality and performance, also consider:
- Performance per watt: How much computing power per watt
- Thermal design power: Cooling system requirements
- Scalability: Ability to flexibly adjust based on power supply

## üéØ Summary: GPU Millionaires' Sweet Burden

Microsoft CEO's "sweet burden" reveals a profound contradiction in the AI era: The speed of technological progress far exceeds the pace of infrastructure construction. In the AI era, owning the most advanced hardware is just the first step to success. The real competitive advantage lies in the ability to build a complete infrastructure ecosystem.

This reminds us: Technological development is not just a competition of algorithms and hardware, but also a competition of infrastructure and resource allocation. In the AI world, electricity is the new oil, and data centers are the new refineries!

Future AI giants will need to not only write code and design chips, but also build power plants, manage power grids, and optimize energy consumption. This is what a truly "full-stack" engineer looks like! üöÄ
